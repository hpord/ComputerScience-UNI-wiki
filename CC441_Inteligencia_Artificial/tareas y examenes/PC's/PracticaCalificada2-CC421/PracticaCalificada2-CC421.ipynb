{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√°ctica Calificada de Inteligencia Artificial\n",
    "\n",
    "Nombre y apellidos: S√°nchez Sau√±e Cristhian Wiki\n",
    "\n",
    "#### Indicaciones:\n",
    "\n",
    "* Entregar en este cuaderno todas tus respuestas teoricas. No se aceptan otro tipo de formato.\n",
    "* En esta tarea hay  programas de codificaci√≥n. Debes presentar pruebas de tus soluciones como el correcto funcionamiento con distintos ejemplos.\n",
    "* Debes responder todas los √≠tems de las preguntas.\n",
    "* Todo acto de COPIA implica la nota de $0A$. Evita copiar de p√°ginas web!.\n",
    "\n",
    "* Todas las lecturas dadas ser√°n tomadas en cuenta en esta evaluaci√≥n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Traduzca la siguiente expresi√≥n l√≥gica de descripci√≥n a l√≥gica de primer orden y explica el resultado:\n",
    "\n",
    "```\n",
    "And(Man, AtLeast (3, Son), AtMost(2, Daughter ),\n",
    "    All(Son, And(Unemployed , Married , All(Spouse, Doctor ))),\n",
    "    All(Daughter , And(Professor , Fills(Department , Physics, Math)))).\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu soluci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ejecuta el descenso de gradiente para minimizar la funci√≥n:\n",
    "\n",
    "$$g(w) = \\frac{1}{50}(w^4 + w^2 +10w)$$\n",
    "\n",
    "con un punto inicial $w_0 = 2$ y $1000$ iteraciones. Haga tres corridas separadas usando cada uno de los valores del tama√±o de paso $\\lambda = 1$, $\\lambda = 10^{-1}$ y $\\lambda = 10^{-2}$. Calcula la derivada de esta funci√≥n a mano e implementa esto (as√≠ como la funci√≥n ) en Python usando NumPy.\n",
    "\n",
    "Traza la gr√°fica del historial de la funci√≥n de costo resultante de cada ejecuci√≥n en una sola figura para comparar su desempe√±o. ¬øQu√© valor del tama√±o de paso funciona mejor para esta funci√≥n y punto inicial en particular?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import decimal\n",
    "decimal.getcontext().prec = 100\n",
    "\n",
    "\n",
    "# Debemos dise√±ar la regla de actualizaci√≥n y las derivadas necesarias\n",
    "\n",
    "g = lambda X: (X**4 + X**2 + 10*X)/50.0\n",
    "d_g = lambda X: (4*(X**3) + 2*X + 10)/50.0   # igualando a 0, tenemos que el m√≠nimo vale -0.16996928431321037, para w=-1.2348\n",
    "cost = lambda X: 0.5*((-0.16996928431321037 - g(X))**2)\n",
    "d_cost = lambda X: -(-0.16996928431321037 - g(X))*d_g(X)\n",
    "\n",
    "class MinFunction:\n",
    "    def __init__(self, lambda_param, g_function=g, d_g_function=d_g, cost_function=cost, d_cost=d_cost, w_0=2.0):\n",
    "        self.lambda_param = lambda_param\n",
    "        self.g_function = g_function\n",
    "        self.d_g_function = d_g_function\n",
    "        self.cost_function = cost_function\n",
    "        self.d_cost = d_cost\n",
    "        self.w = w_0\n",
    "        \n",
    "    def fit(self):\n",
    "        cost_hist = {}\n",
    "        for i in range(1, 1001): \n",
    "            #print(self.w)\n",
    "            self.w -= self.lambda_param*self.d_cost(self.w)\n",
    "            np.round(self.w, 4)\n",
    "            if i%50 == 0:\n",
    "                print(\"G({}) : {} \".format(round(self.w, 4), round(self.g_function(self.w), 4)), end=\"\\t\")\n",
    "                print(\"G'({}) : {} \".format(round(self.w, 4), round(self.d_g_function(self.w), 4)), end=\"\\t\")\n",
    "                print(\"Cost({}) : {} \".format(round(self.w, 4), round(self.cost_function(self.g_function(self.w)), 4)), end=\"\\n\")\n",
    "                cost_hist[i] = self.cost_function(self.g_function(self.w))\n",
    "        return cost_hist\n",
    "    \n",
    "    def predict(self):\n",
    "        return self.g_function(self.w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mostrando resultados para lambda 1 \n",
      "\n",
      "G(-0.6072) : -0.1114 \tG'(-0.6072) : 0.1578 \tCost(-0.6072) : 0.0109 \n",
      "G(-0.8611) : -0.1464 \tG'(-0.8611) : 0.1145 \tCost(-0.8611) : 0.01 \n",
      "G(-0.9546) : -0.1561 \tG'(-0.9546) : 0.0922 \tCost(-0.9546) : 0.0097 \n",
      "G(-1.0041) : -0.1603 \tG'(-1.0041) : 0.0789 \tCost(-1.0041) : 0.0096 \n",
      "G(-1.0353) : -0.1626 \tG'(-1.0353) : 0.0698 \tCost(-1.0353) : 0.0095 \n",
      "G(-1.0571) : -0.1641 \tG'(-1.0571) : 0.0632 \tCost(-1.0571) : 0.0095 \n",
      "G(-1.0734) : -0.1651 \tG'(-1.0734) : 0.0581 \tCost(-1.0734) : 0.0095 \n",
      "G(-1.0861) : -0.1658 \tG'(-1.0861) : 0.0541 \tCost(-1.0861) : 0.0094 \n",
      "G(-1.0963) : -0.1663 \tG'(-1.0963) : 0.0507 \tCost(-1.0963) : 0.0094 \n",
      "G(-1.1047) : -0.1667 \tG'(-1.1047) : 0.0479 \tCost(-1.1047) : 0.0094 \n",
      "G(-1.1119) : -0.1671 \tG'(-1.1119) : 0.0456 \tCost(-1.1119) : 0.0094 \n",
      "G(-1.118) : -0.1674 \tG'(-1.118) : 0.0435 \tCost(-1.118) : 0.0094 \n",
      "G(-1.1233) : -0.1676 \tG'(-1.1233) : 0.0417 \tCost(-1.1233) : 0.0094 \n",
      "G(-1.128) : -0.1678 \tG'(-1.128) : 0.0401 \tCost(-1.128) : 0.0094 \n",
      "G(-1.1322) : -0.1679 \tG'(-1.1322) : 0.0386 \tCost(-1.1322) : 0.0094 \n",
      "G(-1.1359) : -0.1681 \tG'(-1.1359) : 0.0373 \tCost(-1.1359) : 0.0094 \n",
      "G(-1.1393) : -0.1682 \tG'(-1.1393) : 0.0361 \tCost(-1.1393) : 0.0094 \n",
      "G(-1.1423) : -0.1683 \tG'(-1.1423) : 0.0351 \tCost(-1.1423) : 0.0094 \n",
      "G(-1.1451) : -0.1684 \tG'(-1.1451) : 0.0341 \tCost(-1.1451) : 0.0094 \n",
      "G(-1.1476) : -0.1685 \tG'(-1.1476) : 0.0332 \tCost(-1.1476) : 0.0094 \n",
      "\n",
      "\n",
      "Mostrando resultados para lambda 0.1 \n",
      "\n",
      "G(0.8178) : 0.1859 \tG'(0.8178) : 0.2765 \tCost(0.8178) : 0.0216 \n",
      "G(0.442) : 0.0931 \tG'(0.442) : 0.2246 \tCost(0.442) : 0.0178 \n",
      "G(0.1891) : 0.0386 \tG'(0.1891) : 0.2081 \tCost(0.1891) : 0.0158 \n",
      "G(-0.003) : -0.0006 \tG'(-0.003) : 0.1999 \tCost(-0.003) : 0.0144 \n",
      "G(-0.1547) : -0.0304 \tG'(-0.1547) : 0.1935 \tCost(-0.1547) : 0.0134 \n",
      "G(-0.2763) : -0.0536 \tG'(-0.2763) : 0.1873 \tCost(-0.2763) : 0.0127 \n",
      "G(-0.3749) : -0.0718 \tG'(-0.3749) : 0.1808 \tCost(-0.3749) : 0.0121 \n",
      "G(-0.4557) : -0.0861 \tG'(-0.4557) : 0.1742 \tCost(-0.4557) : 0.0117 \n",
      "G(-0.5224) : -0.0975 \tG'(-0.5224) : 0.1677 \tCost(-0.5224) : 0.0113 \n",
      "G(-0.5782) : -0.1067 \tG'(-0.5782) : 0.1614 \tCost(-0.5782) : 0.0111 \n",
      "G(-0.6254) : -0.1142 \tG'(-0.6254) : 0.1554 \tCost(-0.6254) : 0.0109 \n",
      "G(-0.6656) : -0.1203 \tG'(-0.6656) : 0.1498 \tCost(-0.6656) : 0.0107 \n",
      "G(-0.7002) : -0.1254 \tG'(-0.7002) : 0.1445 \tCost(-0.7002) : 0.0105 \n",
      "G(-0.7303) : -0.1297 \tG'(-0.7303) : 0.1396 \tCost(-0.7303) : 0.0104 \n",
      "G(-0.7567) : -0.1333 \tG'(-0.7567) : 0.1351 \tCost(-0.7567) : 0.0103 \n",
      "G(-0.7801) : -0.1364 \tG'(-0.7801) : 0.1308 \tCost(-0.7801) : 0.0102 \n",
      "G(-0.8008) : -0.1391 \tG'(-0.8008) : 0.1269 \tCost(-0.8008) : 0.0102 \n",
      "G(-0.8194) : -0.1414 \tG'(-0.8194) : 0.1232 \tCost(-0.8194) : 0.0101 \n",
      "G(-0.8361) : -0.1435 \tG'(-0.8361) : 0.1198 \tCost(-0.8361) : 0.01 \n",
      "G(-0.8512) : -0.1453 \tG'(-0.8512) : 0.1166 \tCost(-0.8512) : 0.01 \n",
      "\n",
      "\n",
      "Mostrando resultados para lambda 0.01 \n",
      "\n",
      "G(1.6808) : 0.5523 \tG'(1.6808) : 0.6471 \tCost(1.6808) : 0.0416 \n",
      "G(1.4883) : 0.4401 \tG'(1.4883) : 0.5233 \tCost(1.4883) : 0.0345 \n",
      "G(1.3488) : 0.3724 \tG'(1.3488) : 0.4503 \tCost(1.3488) : 0.0307 \n",
      "G(1.2387) : 0.3255 \tG'(1.2387) : 0.4016 \tCost(1.2387) : 0.0282 \n",
      "G(1.147) : 0.2903 \tG'(1.147) : 0.3666 \tCost(1.147) : 0.0264 \n",
      "G(1.0682) : 0.2625 \tG'(1.0682) : 0.3402 \tCost(1.0682) : 0.0251 \n",
      "G(0.9988) : 0.2396 \tG'(0.9988) : 0.3197 \tCost(0.9988) : 0.024 \n",
      "G(0.9366) : 0.2202 \tG'(0.9366) : 0.3032 \tCost(0.9366) : 0.0231 \n",
      "G(0.88) : 0.2035 \tG'(0.88) : 0.2897 \tCost(0.88) : 0.0224 \n",
      "G(0.828) : 0.1887 \tG'(0.828) : 0.2785 \tCost(0.828) : 0.0217 \n",
      "G(0.7798) : 0.1755 \tG'(0.7798) : 0.2691 \tCost(0.7798) : 0.0212 \n",
      "G(0.7348) : 0.1636 \tG'(0.7348) : 0.2611 \tCost(0.7348) : 0.0207 \n",
      "G(0.6925) : 0.1527 \tG'(0.6925) : 0.2543 \tCost(0.6925) : 0.0202 \n",
      "G(0.6526) : 0.1427 \tG'(0.6526) : 0.2483 \tCost(0.6526) : 0.0198 \n",
      "G(0.6147) : 0.1334 \tG'(0.6147) : 0.2432 \tCost(0.6147) : 0.0194 \n",
      "G(0.5787) : 0.1247 \tG'(0.5787) : 0.2387 \tCost(0.5787) : 0.0191 \n",
      "G(0.5443) : 0.1165 \tG'(0.5443) : 0.2347 \tCost(0.5443) : 0.0187 \n",
      "G(0.5114) : 0.1089 \tG'(0.5114) : 0.2312 \tCost(0.5114) : 0.0184 \n",
      "G(0.4798) : 0.1016 \tG'(0.4798) : 0.228 \tCost(0.4798) : 0.0181 \n",
      "G(0.4494) : 0.0947 \tG'(0.4494) : 0.2252 \tCost(0.4494) : 0.0179 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos para diferentes valores de lambda\n",
    "lambda_values = [1, 0.1, 0.01]\n",
    "hist = []\n",
    "for l in lambda_values:\n",
    "    print(\"Mostrando resultados para lambda {} \\n\".format(l))\n",
    "    min_f = MinFunction(lambda_param=l)\n",
    "    hist.append(min_f.fit())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAABD/klEQVR4nO3dd3gVVfrA8e+bQkJNKAFCAgSpUhSQErGBFVCKvRdQsSy2dXWtK+vuT9F1rWtZWAVRsIsK9gJio6p0kUiRQIQQegkhyfv740xubkLKvZDLTXk/zzPPnXJm5swE7nvPmTPniKpijDHGBCoi3BkwxhhTtVjgMMYYExQLHMYYY4JigcMYY0xQLHAYY4wJigUOY4wxQbHAYcwhEBEVkXbe/Asicr/fthtEZKOI7BKRxuHLZcURkTEi8mqIjr1GRE4NIr3v3pvDywKHOaxEZKaIXBPufISCql6vqv8AEJFo4HHgdFWtp6pZhzMvwX4JGxMMCxymxhKRyBAevhkQCyw9mJ1DnDdjDokFDlMmEWkpIu+KSKaIZInIf7z1ESJyn4isFZFNIjJJROK8bbEi8qqXfpuIzBORZiLyf8AJwH+86puCY3USkc9FZIuIrBCRC8rIz0wReVhE5orIdhF5X0Qa+W1/S0T+8LbNEpEuftsmisjzIvKRiOwGBojImSLyk4jsEJF1IjKmnPtxh4hkiMgGERlZbNtEEfmniHQAVnirt4nIV+VdZyl5ayEi73j3frWI3OyXfoyIvOnd950islREennbXgFaAdO8+3yntz5VRL73/iYLRaS/3/GuEpFV3rFWi8ilZd2HIO73cyLysZeP70SkuYg8KSJbReQXEelR7JC9RWSZt32CiMQGeO+D+juaQ6SqNtlU4gREAguBJ4C6uF/Qx3vbRgJpwBFAPeBd4BVv23XANKCOd4xjgAbetpnANX7nqAusA0YAUUBPYDPQpZQ8zQTWA129fd8BXvXbPhKoD8QATwI/+22bCGwHjsP9aIoF+gPdvOWjgI3A8FLOPdDbXnDuKYAC7fyO/09vPsXbFhXIdZaQtzrAAuBvQC3vPq8CzvDSjwGygcHePX4YmO2X1zXAqX7LSUCWlz4COM1bTvDytgPo6KVNLOP+jwnyfm/2/v6xwFfAauAKL8//BGYUy/MSoCXQCPjO736Wd+8D/jvaVAHfDeHOgE2VdwKOBTILvvyKbfsSuNFvuSOw3/tSHAl8DxxVwn4zKRo4LgS+KZbmv8ADpeRpJjDWb7kzkANElpA23vtyifOWJwKTyrnmJ4EnStn2UrFzdyDwwFHmdRbPG9AX+L1Y+ruBCd78GOCLYvdhr9/yGooGjr/iBXa/dZ8CV3pfxNuAc4Ha5dyfMfgFjgDu93i/7TcBy/2WuwHbiuX5er/lwcBvgdz7YP6ONh36ZFVVpiwtgbWqmlvCthbAWr/ltbig0Qx4Bfel9LpXrfCouIfFJWkN9PWqT7aJyDbgUqB5GflaV+y80UATEYkUkbEi8puI7MB9EQE0KWVfRKSviMzwqoO2A9cXS1/8moufO1CBXOe6YulbFEt/D+7+FvjDb34PECsiUWWc//xixzseSFTV3bjAdj2QISIfikin8i4owPu90W9+bwnL9Yodtvj9beHNl3nvg/w7mkNkgcOUZR3QqpQvow24L6MCrYBcYKOq7lfVv6tqZ6AfcBauegLcr8Ti5/haVeP9pnqqekMZ+WpZ7Lz7cVUilwDDgFOBONyvfgDxS1/8/FOAD4CWqhoHvFAsvb+MEs4dqECuU4ulX10sfX1VHRzg+Uq6z68UO15dVR0LoKqfquppuGqqX4DxAZwjkPsdrOL3d4M3X969D+bvaA6RBQ5Tlrm4/7BjRaSuuIfex3nbXgNuE5E2IlIPeAh4Q1VzRWSAiHQT1zJoB+6LPc/bbyOuvr7AdKCDiFwuItHe1FtEjiwjX5eJSGcRqQM8CLytqnm4uvZ9uLr7Ol6eylMf2KKq2SLSB/dlWJo3gav8zv1AAMcvEOx1zgV2iMhfRaS29+u+q4j0DvB8xe/zq8AQETnDO1asiPQXkWRxDReGikhd3P3bReHfqywHc7/L8ycvT41wJaw3vPXl3ftg/o7mEFngMKXyvoyHAO2A34F0XJUGuDrnV4BZuAee2bg6bHDVL2/jgsZy4GvcFxfAU8B5XquZp1V1J3A6cBHu1+UfwCO4h62leQVXf/4H7qFrQWujSbgqjPXAMmB2AJd5I/CgiOzEPYh+s7SEqvoxru78K1zDgK8COH7BvkFdp9+97467v5uB/+F+2QfiYeA+r1rqL6q6Dlc6uAf33GodcAfuOyACuN3L1xbgJNx9Kc/B3O/yTAE+wzUEWIV7gB7IvQ/472gOnajaQE6m6hCRmbiHs/8Ld16MqamsxGGMMSYoFjiMMcYExaqqjDHGBMVKHMYYY4JS2stC1UqTJk00JSUl3NkwxpgqZcGCBZtVNaH4+hoROFJSUpg/f364s2GMMVWKiJTYO4JVVRljjAmKBQ5jjDFBscBhjDEmKDXiGYcxpnLav38/6enpZGdnhzsrNVpsbCzJyclER5fWiXVRFjiMMWGTnp5O/fr1SUlJQcQ6sw0HVSUrK4v09HTatGkT0D5WVWWMCZvs7GwaN25sQSOMRITGjRsHVeqzwGGMCSsLGuEX7N/AAkd58vMhL5ChCYwxpmawwFGWcePgiCPgvffCnRNjTIjUq1d89NqDM2bMGB577LFy01111VW8/fbbAR931qxZ9OzZk6ioqKD2CyULHGXZswfWroVJk8KdE2NMDdWqVSsmTpzIJZdUnkENLXCU5eKLITISPvoIMjPDnRtjTAjt2rWLU045hZ49e9KtWzfef/99ANasWUOnTp245ppr6Nq1K5deeilffPEFxx13HO3bt2fu3Lm+YyxcuJCTTz6Z9u3bM368G7ZdVRk9ejSdO3fmzDPPZNOmTb70Dz74IL1796Zr166MGjWKknorT0lJ4aijjiIiovJ8XVeenFRGzZrBwIGQmwuvvRbu3BhT7YlIqdO4ceN86caNG1dm2oMRGxvL1KlT+fHHH5kxYwa3336774s8LS2NW265hUWLFvHLL78wZcoUvv32Wx577DEeeqhwqPVFixbx4Ycf8sMPP/Dggw+yYcMGpk6dyooVK1i8eDHjx4/n+++/96UfPXo08+bNY8mSJezdu5fp06cf5J07vCxwlOeKK9ynVVcZU62pKvfccw9HHXUUp556KuvXr2fjxo0AtGnThm7duhEREUGXLl045ZRTEBG6devGmjVrfMcYNmwYtWvXpkmTJgwYMIC5c+cya9YsLr74YiIjI2nRogUnn3yyL/2MGTPo27cv3bp146uvvmLp0qWH+7IPir0AWJ4hQyAuDhYsgKVLoUuXcOfImGor0IHlRo0axahRoyr03JMnTyYzM5MFCxYQHR1NSkqK792GmJgYX7qIiAjfckREBLm5ub5txUs7BcsllYKys7O58cYbmT9/Pi1btmTMmDFV5g16K3GUp3ZtuOACN19JWjQYYyre9u3badq0KdHR0cyYMYO1a0vsUbxM77//PtnZ2WRlZTFz5kx69+7NiSeeyOuvv05eXh4ZGRnMmDEDwBckmjRpwq5duypNi6lAhDRwiMhAEVkhImkiclcJ20VEnva2LxKRnsW2R4rITyIy3W9dIxH5XERWep8NQ3kNANx6K3z2Gdx3X8hPZYwJj0svvZT58+fTq1cvJk+eTKdOnYI+Rp8+fTjzzDNJTU3l/vvvp0WLFpx99tm0b9+ebt26ccMNN3DSSScBEB8fz7XXXku3bt0YPnw4vXv3LvGY8+bNIzk5mbfeeovrrruOLpWg1iNkY46LSCTwK3AakA7MAy5W1WV+aQYDNwGDgb7AU6ra12/7n4FeQANVPctb9yiwRVXHesGooar+tay89OrVS20gJ2Mqn+XLl3PkkUeGOxuGkv8WIrJAVXsVTxvKEkcfIE1VV6lqDvA6MKxYmmHAJHVmA/EikuhlOBk4E/hfCfu87M2/DAwPUf5LtmfPYT2dMcZUNqEMHEnAOr/ldG9doGmeBO4E8ovt00xVMwC8z6YlnVxERonIfBGZn1kR72Dk5MDZZ0NSEuzceejHM8aYKiqUgaOkxtTF68VKTCMiZwGbVHXBwZ5cVcepai9V7ZWQcMBY68GrVQs2b4Zt2+Dddw/9eMYYU0WFMnCkAy39lpOBDQGmOQ4YKiJrcFVcJ4vIq16ajX7VWYnAJg4Xe6fDGGNCGjjmAe1FpI2I1AIuAj4oluYD4AqvdVUqsF1VM1T1blVNVtUUb7+vVPUyv32u9OavBN4P4TUUdf75EBMDM2bA778fttMaY0xlErLAoaq5wGjgU2A58KaqLhWR60Xkei/ZR8AqIA0YD9wYwKHHAqeJyEpci62xFZ750sTHw7BhoAqTJx+20xpjTGUS0vc4VPUjVe2gqm1V9f+8dS+o6gvevKrqn7zt3VT1gDazqjqzoCmut5ylqqeoanvvc0sor+EAV3qFnUmTXAAxxlRplb1b9X379nHhhRfSrl07+vbtW6SLE3/33nsvLVu2rLDrKYu9OR6s00+Hpk1hxQo3GWNMCL344os0bNiQtLQ0brvtNv7615JfWxsyZEiRnnpDyQJHsKKiXE+569bBQbxZaoypnCprt+rvv/8+V3o1Heeddx5ffvllielSU1NJTEys0HtSGuvk8GD49W5pjKk48vfSu0T/71n/ZdQxrmPDcQvGcd3060pNqw8EX41c0K16gwYN2Lx5M6mpqQwdOhRw3aq/9dZbjBs3jt69e/u6Vf/ggw946KGHeM8bJXTRokXMnj2b3bt306NHD84880xmz57t61Z948aNdO7cmZEjRwKuW/W//e1vAFx++eVMnz6dIUOGFMnX+vXradnSNT6NiooiLi6OrKwsmjRpEvQ1VhQrcRwKVfdehzGmyqus3aqXVLo42DFHKoqVOA7W99/D5ZfD0UfbC4HGVJBASwqjjhnlK31UlMrarXpycjLr1q0jOTmZ3Nxctm/fTqNGjQ79gg+BlTgOVkoKrFkD06dDVla4c2OMOUSVtVv1oUOH8vLLrnu+t99+m5NPPjnsJQ4LHAerRQs47TTYvx/eeCPcuTHGHKLK2q361VdfTVZWFu3atePxxx9n7NjCV9e6d+/um7/zzjtJTk5mz549JCcnM2bMmKDzH6iQdatemYSsW/UpU+DSS6FvX5g9u+KPb0w1Z92qVx6VpVv16m/4cKhXD+bMsXc6jDE1hgWOQ1Gnjuu/CqzjQ2NMjWGB41AVdEHyxRfhzYcxxhwmFjgO1QknuPHIv/su3DkxxpjDwt7jOFQREa51lTHG1BBW4qhIW7ZACS/wGGNMdWKBo6Lcfz80bw7vvBPunBhjglBdulVfsGAB3bp1o127dtx8882+rkpmzZpFz549iYqKCuq8ZbHAUVFatHAvA1rrKmNMBQq0W/UbbriBcePGsXLlSlauXMknn3wCQKtWrZg4cSKXXHJJheXJAkdFufBCiI52ravWrw93bowxQarK3apnZGSwY8cOjj32WESEK664wtdjb0pKCkcddRQRERX3dW+Bo6I0agRDhkB+vnuj3BgTPJHSp3HjCtONG1d22oNQ0K36jz/+yIwZM7j99tt9X9BpaWnccsstLFq0iF9++cXXrfpjjz3GQw895DvGokWL+PDDD/nhhx948MEH2bBhA1OnTvV1qz5+/Hi+//57X/rRo0czb948lixZwt69e5k+ffoB+SqtW/XiaZKTk33LycnJrA/hD1gLHBXpiivc58sv27CyxlQxVblb9cPd9bo1x61IgwZB48awdCn8/DP06BHuHBlTtQT6g2vUKDdVoKrcrXpycjLp6em+5fT0dFq0aBHsLQiYlTgqUq1acPHFrqhsLwQaU6VU5W7VExMTqV+/PrNnz0ZVmTRpEsOGDQs6/4EKaeAQkYEiskJE0kTkrhK2i4g87W1fJCI9vfWxIjJXRBaKyFIR+bvfPmNEZL2I/OxNg0N5DUG78043Tsfo0eHOiTEmCFW9W/Xnn3+ea665hnbt2tG2bVsGDRoEwLx580hOTuatt97iuuuuo0uXLkFfV3Eh61ZdRCKBX4HTgHRgHnCxqi7zSzMYuAkYDPQFnlLVvuLCaV1V3SUi0cC3wC2qOltExgC7VLX8BtOekHWrbow5JNateuVRWbpV7wOkqeoqVc0BXgeKl52GAZPUmQ3Ei0iit7zLSxPtTVXrabMqrFwZ7lwYY0yFC2XgSALW+S2ne+sCSiMikSLyM7AJ+FxV5/ilG+1Vbb0kIg0rPOeHKjsbOneGbt1g69Zw58YYYypUKANHSW3BipcaSk2jqnmq2h1IBvqISFdv+/NAW6A7kAH8u8STi4wSkfkiMj8zMzP43B+K2FhISoJ9++Cttw7vuY2pYmrCKKSVXbB/g1AGjnSgpd9yMrAh2DSqug2YCQz0ljd6QSUfGI+rEjuAqo5T1V6q2ishIeEQLuMgFYzTYV2QGFOq2NhYsrKyLHiEkaqSlZVFbGxswPuE8j2OeUB7EWkDrAcuAop3lvIBrtrpddzD8e2qmiEiCcB+Vd0mIrWBU4FHALxnIBne/mcDS0J4DQfv7LOhbl3XLHf+fOh1wPMlY2q8gvcPDnutgCkiNja2yJvn5QlZ4FDVXBEZDXwKRAIvqepSEbne2/4C8BGuRVUasAcY4e2eCLzstcyKAN5U1YJ38R8Vke64Kq01wHWhuoZDUq8eXH89/PvfrvSxYIGrwjLG+ERHR9OmTZtwZ8MEKWTNcSuTsDXH3bPHvT3+66/wl7/Av/51+PNgjDEHKRzNcU2dOu4ZR/PmkJoa7twYY0yFsL6qQq1vX1i92qqpjDHVhpU4Dgf/oGFjdRhjqjgLHIfTI49Amzbw2Wfhzokxxhw0CxyHU36+G1525EjYti3cuTHGmINigeNwuuMO95B8/Xq4+eZw58YYYw6KBY7DKSrKjQ5Yuza88gpMnRruHBljTNAscBxuHTpAQX/6110HfgPXG2NMVWCBIxxGj4YBAyAzE26/Pdy5McaYoFjgCIeICJgwAYYOhX/+M9y5McaYoNgLgOHSujW8/364c2GMMUGzEkdlkJ8P77zjRg00xphKzgJHZXDhhXDeefDf/4Y7J8YYUy4LHJXB+ee7z7/8BX77Lbx5McaYcljgqAwuuAAuugh274arroK8vHDnyBhjSmWBo7L4z39c9+vffgtPPhnu3BhjTKkscFQWjRvD//7n5u+9F5YuDW9+jDGmFBY4KpMzz4Srr4Z9+6zUYYyptOw9jsrm8cehSxe46aZw58QYY0pkgaOyadAAbrst3LkwxphSWVVVZfbHH3DLLbBzZ7hzYowxPhY4KrPzz4enn4ZTT4UtW8KdG2OMAUIcOERkoIisEJE0EbmrhO0iIk972xeJSE9vfayIzBWRhSKyVET+7rdPIxH5XERWep8NQ3kNYfXyy26o2blz4aSTXAnEGGPCLGSBQ0QigWeBQUBn4GIR6Vws2SCgvTeNAp731u8DTlbVo4HuwEARSfW23QV8qartgS+95erpiCPgm2+gUydYsgROPBF+/z3cuTLG1HChLHH0AdJUdZWq5gCvA8OKpRkGTFJnNhAvIone8i4vTbQ3qd8+L3vzLwPDQ3gN4ZeUBLNmQY8esHIlHH+8+zTGmDAJZeBIAtb5Lad76wJKIyKRIvIzsAn4XFXneGmaqWoGgPfZtKSTi8goEZkvIvMzMzMP9VrCKyEBvvoKjjsO1q2Dt98Od46MMTVYKAOHlLCueL/hpaZR1TxV7Q4kA31EpGswJ1fVcaraS1V7JSQkBLNr5RQfD59+Cs89B3dV39o5Y0zlF8rAkQ609FtOBjYEm0ZVtwEzgYHeqo0ikgjgfdacQbvr1oUbbgDx4u369e4ZiDHGHEahDBzzgPYi0kZEagEXAR8US/MBcIXXuioV2K6qGSKSICLxACJSGzgV+MVvnyu9+SuBmjmM3rZtcNppcPrp8OGH4c6NMaYGCVngUNVcYDTwKbAceFNVl4rI9SJyvZfsI2AVkAaMB2701icCM0RkES4Afa6q071tY4HTRGQlcJq3XPM0aOBaWWVnw/Dh8Oab4c6RMaaGEK0Bw5X26tVL58+fH+5sVDxVuPNOeOwxiIiA8eNh5Mhw58oYU02IyAJV7VV8vb05XpWJwKOPwj/+4cYtv/pqeOqpcOfKGFPNWeCo6kTgvvsKu2G/9VZ7YG6MCSnrHbe6uOUWqF8fVqxwLwkaY0yIWOCoToo/38jMdCMLRljB0hhTcewbpbr64w/o1w8uvxz27g13bowx1YgFjupq1SoXPKZMcf1czZlT/j7GGBMACxzVVb9+rnPEI490zz369YO773bjmRtjzCGwwFGd9egBP/4Id9zh3vkYOxZ69YKffgp3zowxVZgFjuouNta96/Htt9C+vRvXY+PGcOfKGFOFWeCoKfr1g59/htdfh4EDC9dX9S7njTGHnQWOmqROHbjwwsLl77+HVq3g4YchNzd8+TLGVCkBBw4RqS0iHUOZGXOYzZjhOkm85x43SNTy5eHOkTGmCggocIjIEOBn4BNvubuIFO8i3VQ1994Ln30GLVvC3LnuYfq//w15eeHOmTGmEgu0xDEGN4b4NgBV/RlICUWGzGF22mmweLF763zfPvjLX+Ckk2Dt2nDnzBhTSQUaOHJVdXtIc2LCJy4OXnwRpk+HxERXZRUTE+5cGWMqqUADxxIRuQSIFJH2IvIM8H0I82XC4cwzXXPdDz6A5s3dut27YcGC8ObLGFOpBBo4bgK6APuAKcB24JZQZcqEUaNG7kF5gWeecS8NnnOOq9IyxtR4gQaOM1X1XlXt7U33AUNDmTFTSeTmupcIp06Fo4+GSy6BX38Nd66MMWEUaOC4O8B1prq57z7XYeLo0RAdDa+95vq/GjEC1qwJd+6MMWFQZuAQkUHe84wkEXnab5oI2BtjNUVioquyWrkSrr3Wje8xcaJ7E90YU+OUV+LYAMwHsoEFftMHwBmhzZqpdFq1gnHj4Jdf4P77Ydiwwm1vvGF9YBlTQ4iqlp9IJFpV93vzDYGWqroo1JmrKL169dL58+eHOxvVV1oadOrkmvDedJPrjbdx43DnyhhziERkgar2Kr4+0Gccn4tIAxFpBCwEJojI4wGcdKCIrBCRNBG5q4Tt4lV9pYnIIhHp6a1vKSIzRGS5iCwVkVv89hkjIutF5GdvGhzgNZhQOuss2LMHHnkE2rSBBx6A7fbqjzHVUaCBI05VdwDnABNU9Rjg1LJ2EJFI4FlgENAZuFhEOhdLNgho702jgOe99bnA7ap6JJAK/KnYvk+oandv+ijAazCh0q4dvPee67Zk4EDYuRMefNAFkMceC3fujDEVLNDAESUiicAFwPQA9+kDpKnqKlXNAV4HhhVLMwyYpM5sIF5EElU1Q1V/BFDVncByICnA85pw6d0bPv4YvvnGdVuydWvRQaNU3WSMqdICDRwPAp8Cv6nqPBE5AlhZzj5JwDq/5XQO/PIvN42IpAA9AP9Bs0d7VVsvec9cDiAio0RkvojMz7QxJw6v4493Pe9+8QX89a+F699/33Wk+MILrlRijKmSAgocqvqWqh6lqjd4y6tU9dxydpOSDhVMGhGpB7wD3OpVlYGrzmoLdAcygH+XkudxqtpLVXslJCSUk1VT4UTglFPgqKMK102ZAgsXwg03QFIS3HijvY1uTBUUaLfqySIyVUQ2ichGEXlHRJLL2S0daOm3nIxr3htQGhGJxgWNyar6bkECVd2oqnmqmg+Mx1WJmarglVdc8DjhBFfieP55F1iOP951sGiMqRICraqagHt3owWuKmmat64s84D2ItJGRGoBF3nH8PcBcIXXuioV2K6qGSIiwIvAclUt0nrLe9ZS4GxgSYDXYMItJgYuvhhmzXIljRtvhPr14bvvYNmywnT2HMSYSi3QwJGgqhNUNdebJgJl1v+oai4wGvdsZDnwpqouFZHrReR6L9lHwCogDVd6uNFbfxxwOXByCc1uHxWRxSKyCBgA3BbgNZjKpGtXePZZWL/ePfMYMaJw2z//CYMHw7RpNqiUMZVQoC8AfgFMBF7zVl0MjFDVU0KXtYpjLwBWIarQvj389ptbbtnSjZN+4YVwzDHu2Ykx5rA41BcAR+Ka4v6BeyB9HjCizD2MORgiMHs2PPootG0L69a5d0F693bvi7z7bvnHMMaEVKCB4x/AlaqaoKpNcYFkTMhyZWq2Jk1ctyW//ureCRk92g0stWqVeyZSYOFCN/CUMeawCjRwHKWqWwsWVHUL7t0KY0InIsK1uHrmGUhPd++GDBhQuP3++6FbN+jSBf7+d9f5ojEm5AINHBH+L9p5fVZFhSZLxpQgMhL694co75+dquutt1Ej1yJrzBg3TsjRR8P//R+sXh3O3BpTrQUaOP4NfC8i/xCRB3HjjT8aumwZUw4R+M9/4I8/XDcnV10FcXGwaJEbfGrq1MK02dnWxNeYChTom+OTgHOBjUAmcI6qvhLKjBkTkOho17HihAluPJBp0+Dyy+H88wvT/O1vrnQyapTrjNG6OzHmkATUHLeqs+a4NdzJJ7vnIwWio93b64MGwZAh0LFj+PJmTCVWWnNce05hqr8vvnDD3H70kavWmj0bvvrKTb/95ro+ATeeSH4+1KsX1uwaU9kF+ozDmKorIgJ69nTPPr77DjIz4bXX4Ior4Fy/vjrfesuNXHjaafD447B8uT0bMaYEVlVlTIH773ctsvz/T7Ru7VpznX46XHJJ2LJmTDgc6pvjxlR///gHbNoEkyfDZZe5FxHXroWXX4bx4wvT5ebCSy+5aq4a8MPLmOLsGYcx/po0cSWLSy5xHSwuXAhffw0tWhSm+eknuPpqN5+U5EY77N/ffbZvb/1pmWrPAocxpYmMdM9GevY8cP0557iAsn69G2NkyhS3LTER5s1zAcWYasoChzHB6tkT3nnHtcBatswFkJkz3WdOjgseBYYOdSWQ1FQ39epVtL8tY6ogezheBlVl3IJxpCancnTzo0OQM1OtqMKGDYWljV27ID6+6JgiERGub63UVBg50n0aU0nZexwH4bl5zzH649F0a9qNedfOIyYqJtxZMpWZSNEqqrp1XZPeOXPcNHu2e59k8WI3nXxyYeD49FPXE3BqKvTtCwlljpNmTFhZiaMMu3N2c/QLR/Pb1t+4s9+dPHLaIyHInalR9u51D9dnz4aLLip86D5qVNGWW0cc4QJI375w7LHQp0948mtqtNJKHBY4yvH9uu85YcIJqCqzRszi+FbHV3DujMF1ifLppy6gzJvn3mIv0L9/YZcpOTnw5JPuOUuPHu6FRWNCxALHIbwAeM+X9/Dwtw/TJr4NC69fSP0Ye7hpQig3F5YudUFk7lw35sitt7ptP//sAkaBVq3cckHrr/79rcsUU2EscBxC4MjJy6HP+D4s3LiQa3tey7gh4yowd8YE4ddf4amnXHXXzz+7qi9/y5dDp05u/oMPYN8+F3jatSscy8SYANnD8UNQK7IWr57zKseMO4Z5G+axZ/8e6kTXCXe2TE3UoQM8+6ybz8tzgeTHH10gWbLEvYBY4OGHXakFICYGOneGrl1dIOnf343jbsxBsBJHEL5Z+w19k/tSK7JWBeTKmBD75z/hhx9cQPn996LbbrnFPSsBWLHCzXfr5qauXaFhw+JHMzVQWEocIjIQeAqIBP6nqmOLbRdv+2BgD3CVqv4oIi2BSUBzIB8Yp6pPefs0At4AUoA1wAX+46GH0gmtT/DNFwRcse4lTGV1332F89u3u+cmS5a4psCnn164bc4ceOGFovsmJRUGkb//HepYCdsUClmJQ0QigV+B04B0YB5wsaou80szGLgJFzj6Ak+pal8RSQQSvSBSH1gADFfVZSLyKLBFVceKyF1AQ1X9a1l5qejecbP2ZHHjRzcytMNQLj3q0go7rjFhsWIFfPhh4fsly5YVPjuJjXUvMkZGuuUzz3Qtvjp1cmO8F3wmJ1sfXdVQOEocfYA0VV3lZeB1YBiwzC/NMGCSuug1W0TiRSRRVTOADABV3Skiy4Ekb99hQH9v/5eBmUCZgaOifbjyQ95c+iafpn3Kia1PpGVcy8N5emMqVseORUdBzMuDVatc6WTjxsKgoQqzZrlAMnNm0WPUret6F77tNrecleX2bdcOalnVbnUTysCRBKzzW07HlSrKS5OEFzQARCQF6AHM8VY18wILqpohIk1LOrmIjAJGAbRq1eqgL6Iklx91OW8ve5tpv05jxPsj+Ozyz4gQ66HeVBORke4hu/+D9gJLl7qWW8uXwy+/FM5nZkKDBoXppk2DESPcsVJSCo9XMJ12WmFAMlVOKANHSeXW4vViZaYRkXrAO8CtqrojmJOr6jhgHLiqqmD2LY+IMH7IeLo+35UvV3/Js3Of5aa+N1XkKYypfETceyOtWsEZZxTdlpVVtGSh6t5+X73ajVvy22/wySduW926sHNnYdqbb3ZBpEOHwsDSsqXr18tUSqEMHOmAfx1OMrAh0DQiEo0LGpNV9V2/NBsLqrO8ZyGbKjznAWhWrxnjzhrHOW+ew51f3MlpbU+jU5NO4ciKMeFX/A32ESPclJ3tqr1Wriyc8vMLn4eoukGxdu8uun9MDLRtC3fdBZdf7tZlZcHmza4EE2P9xoVTKAPHPKC9iLQB1gMXAcXH3vwAGO09/+gLbPcCggAvAstV9fES9rkSGOt9vh/CayjT2UeezRVHX8GkhZO4YuoVfH/190RF2KsxxvjExrr3Rzp3Lnl7fr4bYdE/sKxcCX/84R7S5+YWpp06Fa691gWd5GQXWI44wk1t28IFF1gp5TAJ2becquaKyGjgU1xz3JdUdamIXO9tfwH4CNeiKg3XHHeEt/txwOXAYhH52Vt3j6p+hAsYb4rI1cDvwPmhuoZAPD3wab5e8zWpyank5uda4DAmGJGRcO65B67fsQPS0lyVlb+UFPdOyrp1bip4SB8XBxdeWJju3HMLq8vatHFjx6ekuMm6ZDlk9gJgBdixbwcNYhqUn9AYc+j273fBY9Uq9+xk1SpXcnnsMbc9P989R8nOLnn/hx92VWDgHux/8UVhUElJsYG2/FiXIyHkHzR27NtBdEQ0taNrhzFHxlRj0dGuaqptW9c6qySzZhUGlrVrYc2awk//ERq//to9nPfXqJELIK1bwxtvuPOBe98lPt6NlVLDq8QscFSgH9b9wMXvXMzZnc7miYFPhDs7xtRMERGuH66S+uLKz3dTgU6d4PrrXUApmLZscdPq1YVBA9wwwL/+6h7MJye71mUtW7rP00+HE7yeJVSr/cuQFjgqUHRkNOk70nlyzpMM7TiUAW0GhDtLxhh/ERFFSwv9+7upgCps2uQCyLZtRfdt0sS17MrKKmxiXCA2tjBwfPihawlWEFiSkwunpCQ46aQq/1KkBY4K1KtFL+4/8X7GfD2GK9+7ksU3LCYuNi7c2TLGBEoEmjVzU3Hffec+d++G9HT3nKXgQf0Avx+J69a5oLNtGyxadOBxdu8uDBwjR8L69YVBxT/AtG7tqsYqIXs4XsH25+3nuJeOY96GeVx59JVMHD7xsJzXGFNJqLr3TQqCSnq6Cw7p6S6YTJtWmLZ9e9d6rCTXXw/PP+/mV6yABx5wQw2XNIWopZg9HD9MoiOjmXT2JHr8twcvL3yZYR2HcfaRZ4c7W8aYw0XEPUBPSIBjjik77dSpLsD4B5eCyb/Ll19/dQ/qS7NypesXDFxPx2vWuIBSMG59BbMSR4g8PedpbvnkFlLiU0i7KY3ICOuXxxhzkNavd++sbNhQdFq/3n1mZbkmyOCqzQreb7n99sJmygfBShyH2eg+o/kk7RNG9hhpQcMYc2iSkuDSUoZwKN6K6+abXTPlDRvgxBNDkh0rcYRQXn5ekaAxY/UM+ib3tWFnjTFVQmkljpr9FkuI+QeNeevnMXDyQPq92I/ftvxWxl7GGFO5WeA4TGKjYmkV14qFGxdyzLhjmLZiWvk7GWNMJWSB4zDp1qwb86+dz/BOw9m+bztDXx/KvV/eS15+XrizZowxQbHAcRjFxcbx7gXv8sipjxAhETz07UOc8eoZZO7ODHfWjDEmYBY4DjMR4c7j7uTLK76kad2mzNswj63ZW8OdLWOMCZg1xw2T/in9+em6n1ixeQUdGncAoKCFm1TzDtKMMVWblTjCqEX9FkU6Qnxu3nNcNvUydufsLmMvY4wJLytxVBI79u3g/hn3szV7Kwv/WMg7F7xDxyYdw50tY4w5gJU4KokGMQ34duS3dGrSiaWZS+k9vjfvLHsn3NkyxpgDWOCoRDondGbuNXM5v/P57MzZyXlvncefP/0zu3J2hTtrxhjjY4GjkqkfU583znuDJ854gqiIKJ6Y/QQ3fXxTuLNljDE+FjgqIRHh1tRb+WbENxzX8jju6HeHb9uGnRvIzc8NY+6MMTVdSAOHiAwUkRUikiYid5WwXUTkaW/7IhHp6bftJRHZJCJLiu0zRkTWi8jP3jQ4lNcQTqnJqXw78ls6J3QGXHPdC966gM7Pdub1Ja+Tr/nlHMEYYypeyAKHiEQCzwKDgM7AxSLSuViyQUB7bxoFPO+3bSIwsJTDP6Gq3b3powrNeCW2afcmNu7eyMotK7n4nYvp8d8eTP91OjWhh2NjTOURyhJHHyBNVVepag7wOjCsWJphwCR1ZgPxIpIIoKqzgC0hzF+V06xeM5bduIzxQ8aT3CCZRRsXMeS1IRz30nHMXDMz3NkzxtQQoQwcScA6v+V0b12waUoy2qvaeklEGpaUQERGich8EZmfmVl9+oKKjozmmp7XsPKmlTxxxhM0qdOEH9J/YOhrQ9mevT3c2TPG1AChDBwl9ZtRvE4lkDTFPQ+0BboDGcC/S0qkquNUtZeq9kpISCjnkFVPbFQst6beyqqbV/GPAf/ggZMeIC42DoCcvByWZS4Lcw6NMdVVKANHOtDSbzkZ2HAQaYpQ1Y2qmqeq+cB4XJVYjVU/pj73nXgft/e73bdu/ILxdH2uK5dPvdwGjTLGVLhQBo55QHsRaSMitYCLgA+KpfkAuMJrXZUKbFfVjLIOWvAMxHM2sKS0tDXV5j2biYqI4tVFr9LhPx0YNHkQby19i325+8KdNWNMNRCywKGqucBo4FNgOfCmqi4VketF5Hov2UfAKiANV3q4sWB/EXkN+AHoKCLpInK1t+lREVksIouAAcBtobqGquqB/g/w602/clX3q4iUSD5J+4QL3r6AFo+34L/z/xvu7BljqjipCU05e/XqpfPnzw93NsJi857NTFk8hZd+eomFGxfy+rmvc2HXCwFYt30dtaNr06ROkzDn0hhTGYnIAlXtdcB6Cxw1x08ZP3FkwpHERsUCMOL9EUxeNJmhHYcyovsIzmh3BlER1mGyMcYpLXBYlyM1SI/EHr6goarsztlNnubxzvJ3OOu1s2j1RCvu+uIuVmxeEeacGmMqMytx1HDrd6xn0sJJTPh5Aiu3rPStf3rg09zU1zpXNKYmsxKHKVFSgyTuPuFuVoxewTcjvmFk95HUq1WP09qe5kszZfEUnpz9JCs2r7DuTYwxVuIwB9q7fy+1o2v7llP/l8qc9XMAaBPfhkHtBjGo/SAGpAygbq264cqmMSbErMRhAuYfNABu7nszl3S7hMa1G7N622qem/8cQ14bQqNHG/Hod4+GKZfGmHCxJjSmXJd0u4RLul1CXn4e8zfM5+O0j/k47WPmrZ9Hq7hWvnSfpH3Ce7+8x6B2gzjliFOoV6teGHNtjAkVq6oyBy1zdyZ1ouv4qquufv9qXvr5JQCiI6I5ofUJnNH2DPq17EfPxJ7Uia4TzuwaY4JUWlWVlTjMQUuoW7TzyJv63kTr+NZ8nPYxc9Ln8NXqr/hq9VcA9E/pz4wrZwCQm59L2pY0OjTuQIRYbakxVY0FDlNhujfvTvfm3fnbSX8ja08Wn6/6nBmrZzBn/RyOTT7Wl27xxsX0HNeT+Nh4+iT1ITUplb7Jfemb1JfGdRqH8QqMMYGwqipzWKgqIq4X/U/SPmHk+yPJ2HVgf5btGrXj66u+pkX9FgfsZ4w5vKyqyoSV/5f/wHYDWf/n9aTvSGfO+jnMSZ/DnPVzmL9hPpt2b6J5vea+tP1f7s+WvVvoktCFzgmdfZ/tGrUjOjI6DFdijLHAYcJCRGgZ15KWcS05r/N5AOzP28/a7Wt9zz325+1n7vq5ZOdms2RT0d7zoyOieeiUh/hLv78AkLUni027N1lAMeYwsMBhKo3oyGjaNWpXZDnzjkyWZy5nWeYylmYu9X2u2baGhDqFD+en/jKVa6ddS3RENB2bdKRLQhe6JHThyIQjOaLhEfRo3sOqvIypIBY4TKVWr1Y9eif1pndS7yLrd+XsKtIiK1/zSYlPYc22NSzZtKRICSU+Np6tf93qW77545uJiYyhTcM2tIlvwxENj6B1fGtfB5DGmLJZ4DBVUvGXC0cdM4pRx4xiV86uIiWUXzb/UuRN+HzNZ/yP48nOzT7gmC3qt+AfA/7ByB4jAdcBZNqWNJIaJNGifgt7D8UYjwUOU62UVkIpkK/5TBg2gdVbV7Nq6ypWb1vN6m2rWbttLRt2biA6ovD5yAcrPuDGj3yDUhIfG0+L+i1Iqp9EUoMkXhz6oq/UszxzOfVj6tO8XnMb08RUe/Yv3NQoURFRXNT1ogPW5+bnkr4jnfjYeN+6uNg4+rXsx4adG9iwcwPbsrexLXsbyzKX0bh24yJVZWe9dhartq5CEJrVa+YLMIn1EhneaTiD2g8CYFv2Nn7f/jsJdRJoUqeJPcg3VZIFjnKMHz+e+vXrM3z4cGJjrQ68uoqKiCIlPqXIuoI+usC9T5K1N4sNOzewfsd69uzfUyRtYr1E9uzfw8ZdG/lj1x/8sesPfsz4EYDW8a19gWPG6hmc8+Y5vv3iY+NpWrcpCXUSSKibwIRhE3zB65u137A3dy+NajeiYWxDGtZuSFxMHJERkSG6C8YExl4ALENOTg5JSUls3ryZ+Ph4LrroIkaMGEHv3r2thY4p0f68/WzcvZH1O9azYecGMnZlkJqcSs/EngBMWzGNu7+8m027N5G1N4t8zS+y/9579/oe0p8w4QS+/f3bItsFIS42jsuPupynBz0NQMbODMbMHEPD2g1pGNvQBRpvvmHthnRq0smez5iDYi8AHoT8/HzGjBnDhAkTWLBgAS+88AIvvPACnTt35qqrruKqq64iISGh/AOZGiM6MprkBskkN0gucfuQjkMY0nEI4J63bNm7hczdmWTuySRrT1aRll19WvShVmQttu7dytbsrWzdu5Xt+7azLXsbufm5vnTpO9IZ9+O4UvM079p59Grh/u/f8vEtTFkyhbiYOBrENPBNcbFxHNnkSO454R7ffpMXTaZ+TH3q1apH3ei61KtVzzc1iGlg1Ww1mJU4ArR48WImTpzIq6++yqZNmwD44YcfSE1NrYgsGhOQ3PxctmdvR0RoVLsRAH/s+oOpy6f6gsuWvVvcvLf87oXvckTDIwC49N1LmbJ4SonH7teyH9+N/A6A7Nxsav9f7RLTAbw09CVG9BgBwMs/v8zD3z7sCyp1a3lBJroecbFxPH7G47793lz6Jnv376VOdJ0Dpmb1mtG0blPAupqpLEorcYQ0cIjIQOApIBL4n6qOLbZdvO2DgT3AVar6o7ftJeAsYJOqdvXbpxHwBpACrAEuUNWtlKEi+6rav38/H3/8MZ999hnPPPOM7x/3BRdcQPPmzRkxYgQ9evSokHMZU9Gyc7PZsW8HO/btYHv2dt/8jn07iIuNY2jHoYB7T+a66dexY98OdufsZlfOriLT+CHjObfzuQA88u0j3PXlXSWer36t+uy4e4dvuf0z7UnbklZi2j+n/pl/n/FvAL5e8zWnvnIqtaNqUzu6NrFRsdSO8j6ja/PGeW/4xoJ5du6z/Jjxo2+bf9ojGh7B2UeeDbhqxE/SPiEmKoaYyBhiomKIjYr1zTev19xXpWeByznsgUNEIoFfgdOAdGAecLGqLvNLMxi4CRc4+gJPqWpfb9uJwC5gUrHA8SiwRVXHishdQENV/WtZeQl1J4fr1q2jVavCAY2OPvporrrqKi699FKryjLV3rbsbWTszCgSWHbvd8EmLz+P63pd50t79xd3s2HXBvbs33PANLL7SG479jYAPl75MYOnDC71nGtuWUPr+NYAnPPGOUz9ZWqJ6U494lQ+v/xzwHVL0+RfTUo95pvnvcn5Xc4HYOy3Y7n3q3t9QaVWZC3flFAngdnXzPbtd9m7l5G1N4takbWIiSxMGxMZw6D2g3zBeNXWVUxZPMW3PToi2n1Gus+hHYf63k9avHExW7O3Eh0RTXRkNNER0URFRBEdGU39WvVJrJ8IuOrOXTm7fOkiJbJCA144nnH0AdJUdZWXgdeBYcAyvzTDcIFBgdkiEi8iiaqaoaqzRCSlhOMOA/p78y8DM4EyA0eoJScn8+OPPzJhwgQmT57MwoULue2227jjjjvo378/U6ZM8QWQn376ifz8fFq0aEHTpk2JjLQWMqZqi4+NL9KMuSwPn/pwQOkGtR9Ezn057Nm/h+zcbPbm7nWf+/eyN3dvkY4wb+pzE4PbD/Zt90/v34VNhERwVoezyM7NZl/uPvbl7WNf7j63nLePuNg4X9qcvBzyNZ+9ue58/nbl7CqyPHPNTNbvXF/idTSu09gXOFZsXsH9M+4v9ZrX3rrWFzj+NvNvvPfLeyWmO6PtGXxy2ScAbN6zmWaPNSuyPSoiyhdIJp8zmbM6nFXqOQ9WKANHErDObzkdV6ooL00ScGB/24WaqWoGgKpmiEjTkhKJyChgFFCkNBAKIkKPHj3o0aMH//rXv5g+fToTJkzg448/5osvvqB27cK64ttvv50ZM9yARhERETRr1owWLVqQmJjIwIED+dOf/gRAdnY2y5cvJyEhgXr16lG3bl2io+1hpKk5oiOjiYuMI464MtMNaDOAAW0GlHu8hrUbMu3iaQGd+28n/Y17TriHfbn7yMnLIScvh315+3wBxd+Uc6ewK2dXYTpvn315+3yt6QCOaHgE9xx/Dzl5OezP3+8+8/aTk+8+69eq70vbJaELW/Zu8aXZn7/f9+nf8CIvP496ter5tuVrPrn5ueTm57I3dy+hqlEKZeAoqbxU/CoCSXNQVHUcMA5cVVVFHDMQMTExnHvuuZx77rlkZGQwf/586tUr7B6jQ4cObNmyhYyMDDZt2kRGRgYZGS5OtmjRwpful19+oWfPnkWOHR0d7QsiH330Ed26dQPgP//5DzNnzvRtK5jq1atH69atOe881/tsfn4+77//PrVq1SpxatmyJfHx8YALXDk5OURHRxMVFUVUVJTV+ZoaJSoiiqhaUdSlbpnpTmx9YkDH69ikI/93yv8FlPafJ/8zoHSJ9RPZefdO33JB4CgIJKFqhh3KwJEOtPRbTgY2HESa4jYWVGeJSCKw6ZBzGiKJiYkMGTKkyLoXXnjBN5+Tk8PGjRvZsGEDGzZsIDm58JfE/v37Oeqoo8jMzGT37t3s3r2b/fv3s3XrVrZu3UpUVOGfbs6cObzzzjsl5qFfv36+wJGTk8M555xTYjqAiRMncuWVVwIwbtw4brnlliLbIyIiiIqKom7dumzZssW3fsCAAaSlpfkCTMEUGRnJZZddxl/+4ro+X7RoEaNHjyYyMpKIiIgDPp999llf6fC5557j22+/9W0TESIiIoiIiKBDhw7ceeedvmu6/fbbfduKTxdccIGvscIPP/zAJ5984jtewTFFhFq1avnyWXAvtm7dekA6EeHoo4/m+OOPByAjI4Np06b5thWfhg8f7gvG3333HWvWrPFtA3zzTZs2ZcAA96s5NzeXDz74oMh2/3169uzp+7eyevVqli9fXiRtwXxUVBSnnHKK75p++OEH9uzZU2La5ORk2rVz1Trbt29n0aJFJaYD6N69O3XquC+ktLQ0srKyimwvmK9fvz6dOnUCIC8vj4ULFxbZ7v/ZqlUrGjVyrcQyMzPJyMg4IE3Bv8HOnTv7ltPS0sjJySnx/A0bNqRZM1eNs2fPHtLT08s8f61atQDYtGkTu3btOiAtQGxsLImJ3vOF/HzWrfOvMCmatnHjxtSt64LOzp072b59OyUREZKSknzLmzZtIjc3t8j2AnXr1qVBgwaA+7e/dWvp7YIaN25MVGSIvuJVNSQTLiitAtoAtYCFQJdiac4EPsaVPFKBucW2pwBLiq37F3CXN38X8Gh5eTnmmGO0qsvPz9e9e/fq5s2bde3atZqTk+PbNn/+fH3jjTf0pZde0meeeUbHjh2r999/v/75z3/Wxx9/3Jduz549Onz4cB08eLCeeuqpeuKJJ2pqaqr27NlTu3btqtOmTfOlfeaZZ7R+/foaExOjUVFRiisJKqB16tQpkrcOHToU2e4/3Xrrrb50M2fOLDUdoMuWLfOlveSSS0pNd8IJJ/jS7dq1q8xjvvLKK760jz/+eKnpil9Tx44dA7qmr7/+usZd0/Lly31pL7300rBeU6dOnSr871Qdr+lgAfO1hO/UkJU4VDVXREYDn+Ka476kqktF5Hpv+wvAR7gWVWm45rgjCvYXkddwD8GbiEg68ICqvgiMBd4UkauB34HzQ3UNlYmIEBsbS2xsLI0bFx2X+5hjjuGYY44p9xi1a9dm6tSpAZ1v9OjRjB492resquTn55Obm1vk1xDArFmz2LdvH7m5ueTl5fnS5Obm0qRJYSuWo48+mpkzZ5Kfn09eXp7vs2Dev8T1pz/9icGDB5OXl+c7d8Fnwa9IcNV3Tz31lG9b8al79+6+tKmpqTzwwAMHHE9VD3h+dOWVV7Jx48Yi/1kK0h533HG+dM2bN+eaa64p9UdLXFycL22/fv38fwAVSVfwyxwgMjKSs88+u6QfY6hqkfuUkpLCoEGDSkwXExNT5JpSU1NJSko6IB1A27ZtfekaNGjA8ccfX2I6oEjXO23btqVPnz5FthfMd+zY0bcuIiLCV/Ir6ZgNGzb0zTdp0oSuXbsekKb4uQvOLyIlnr9p08LHn7Vr16Z9+/alnt//75+QkECbNm1KPH/z5oUP5UWkyPPT4mkLSmUA9erVK1Kq8Of/DLTg/AWlk+LHrF+/8DlIdHR0kWssLpQNb+wFQGOMMSUqrTluREmJjTHGmNJY4DDGGBMUCxzGGGOCYoHDGGNMUCxwGGOMCYoFDmOMMUGxwGGMMSYoFjiMMcYEpUa8ACgimcDacOcjTJoAm8OdiTCy67frr8nXD4d2D1qr6gGDCtWIwFGTicj8kt78rCns+u36a/L1Q2jugVVVGWOMCYoFDmOMMUGxwFH9jQt3BsLMrr9mq+nXDyG4B/aMwxhjTFCsxGGMMSYoFjiMMcYExQJHFSYiLUVkhogsF5GlInKLt76RiHwuIiu9z4Z++9wtImkiskJEzghf7iuOiESKyE8iMt1brmnXHy8ib4vIL96/hWNr0j0Qkdu8f/9LROQ1EYmtztcvIi+JyCYRWeK3LujrFZFjRGSxt+1p8R/cvDylDXlpU+WfgESgpzdfH/gV6Aw8StFx2R/x5jvjxn6PwY0F/xsQGe7rqID78GdgCjDdW65p1/8ycI03XwuIryn3AEgCVgO1veU3gauq8/UDJwI9gSV+64K+XmAucCwgwMfAoEDzYCWOKkxVM1T1R29+J7Ac9x9pGO7LBO9zuDc/DHhdVfep6mrcWO99DmumK5iIJANnAv/zW12Trr8B7ovkRQBVzVHVbdSgewBEAbVFJAqoA2ygGl+/qs4CthRbHdT1ikgi0EBVf1AXRSb57VMuCxzVhIikAD2AOUAzVc0AF1yAghHtk4B1frule+uqsieBO4F8v3U16fqPADKBCV513f9EpC415B6o6nrgMeB3IAPYrqqfUUOu30+w15vkzRdfHxALHNWAiNQD3gFuVdUdZSUtYV2VbY8tImcBm1R1QaC7lLCuyl6/JwpXbfG8qvYAduOqKkpTre6BV5c/DFcN0wKoKyKXlbVLCeuq7PUHoLTrPaT7YIGjihORaFzQmKyq73qrN3pFUbzPTd76dKCl3+7JuGJ9VXUcMFRE1gCvAyeLyKvUnOsHd03pqjrHW34bF0hqyj04FVitqpmquh94F+hHzbn+AsFeb7o3X3x9QCxwVGFeK4gXgeWq+rjfpg+AK735K4H3/dZfJCIxItIGaI97QFYlqerdqpqsqinARcBXqnoZNeT6AVT1D2CdiHT0Vp0CLKPm3IPfgVQRqeP9fzgF96yvplx/gaCu16vO2ikiqd59u8Jvn/KFu4WATYfUuuJ4XPFyEfCzNw0GGgNfAiu9z0Z++9yLa1mxgiBaUVT2CehPYauqGnX9QHdgvvfv4D2gYU26B8DfgV+AJcAruBZE1fb6gddwz3P240oOVx/M9QK9vHv2G/AfvJ5EApmsyxFjjDFBsaoqY4wxQbHAYYwxJigWOIwxxgTFAocxxpigWOAwxhgTFAscxpRCRL73PlNE5JIKPvY9JZ3LmKrAmuMaUw4R6Q/8RVXPCmKfSFXNK2P7LlWtVwHZM+awsxKHMaUQkV3e7FjgBBH52Rv7IVJE/iUi80RkkYhc56XvL258lCnAYm/deyKywBsvYpS3biyuN9efRWSy/7nE+Zc3tsRiEbnQ79gz/cbdmFwwfoI3rsLX3nk+9et64mYRWebl8fXDd+dMdWclDmNKUVAqKF7i8AJAU1X9p4jEAN8B5wOtgQ+Bruq6sEZEGqnqFhGpDcwDTlLVrOIlDr9znQtcDwwEmnj79AU64rqE6ILrU+g74A5cb8hfA8NUNdMLNGeo6kgR2QC0UdV9IhKvrrt1Yw5ZVLgzYEwVdDpwlIic5y3H4foAysH1A7TaL+3NInK2N9/SS5dVxrGPB17zqrk2isjXQG9gh3fsdAAR+RlIAbYBXYHPvQJIJK47CnBdkEwWkfdwXZEYUyEscBgTPAFuUtVPi6x0JZPdxZZPBY5V1T0iMhOIDeDYpdnnN5+H+/8rwFJVPbaE9GfiBnkaCtwvIl1UNbec8xtTLnvGYUz5duKG5i3wKXCD16U9ItLBGzypuDhgqxc0OgGpftv2F+xfzCzgQu85SgLui7+s3ltXAAkicqyXl2gR6SIiEUBLVZ2BG+gqHrCH8aZCWInDmPItAnJFZCEwEXgKV030o/eAOpOSh938BLheRBbhvuBn+20bBywSkR9V9VK/9VNx40AvxPV8fKeq/uEFngOoao5XZfa0iMTh/k8/iRt//lVvnQBP2DMOU1Hs4bgxxpigWFWVMcaYoFjgMMYYExQLHMYYY4JigcMYY0xQLHAYY4wJigUOY4wxQbHAYYwxJij/D+xUO9/SeVTCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ahora procedemos a graficar\n",
    "plt.plot(hist[0].keys(), hist[0].values(), color='k', linestyle='dashed', linewidth = 2, markersize=10, label = \"lambda 1\")\n",
    "plt.plot(hist[1].keys(), hist[1].values(), color='g', linestyle='dashed', linewidth = 2, markersize=10,label = \"lambda 0.1\")\n",
    "plt.plot(hist[2].keys(), hist[2].values(), color='r', linestyle='dashed', linewidth = 2, markersize=10,label = \"lambda 0.01\")\n",
    "\n",
    "plt.xlabel('iterationes')\n",
    "plt.ylabel('coste') \n",
    "\n",
    "plt.title('coste para diferentes lambda') \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. En clase hemos tratada la regresi√≥n ridge ($l_2$-regularizada) y $l_1$-regularizada (lasso). Existe una versi√≥n h√≠brida llamada *el√°stic net* que usa t√©rminos de regularizaci√≥n $l_1$ y $l_2$:\n",
    "\n",
    "$$J_{EL} = \\Vert \\mathbf{y} -\\mathbf{Xw} \\Vert^2 + \\lambda_1 \\Vert \\mathbf{w} \\Vert_1 + \\lambda_2 \\Vert \\mathbf{w} \\Vert^2$$\n",
    "\n",
    "    Si definimos:\n",
    "\n",
    "$$J_{2} = \\Vert \\mathbf{\\tilde{y}} -\\mathbf{\\tilde{X}w} \\Vert^2  + c\\lambda_1 \\Vert \\mathbf{w} \\Vert_1$$\n",
    "\n",
    "donde $c = (1 + \\lambda_2)^{-1/2}$ y \n",
    "\n",
    "$$\n",
    "\\mathbf{\\tilde{X}} = \\begin{pmatrix}\n",
    "\\mathbf{X}\\\\\n",
    "\\sqrt{\\lambda_2}\\mathbf{I}_d\n",
    "\\end{pmatrix}, \\qquad \\mathbf{\\tilde{y}} =  \\begin{pmatrix}\n",
    "\\mathbf{y}\\\\\n",
    "\\mathbf{0}_{d \\times 1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Muestra que: \n",
    "\n",
    "$$arg \\min_{\\mathbf{w}}J_{EL}(\\textbf{w}) = c(arg \\min_{\\mathbf{w}}J_2(\\mathbf{w})))$$.\n",
    "\n",
    "Esto implica que un problema de *elastic net* puede resolverse como un problema de *lasso*, utilizando datos modificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTA: EN CASO NO SE VISUALICE LA IMAGEN, ESTA SE ENCUENTRA EN LA CARPETA DE LA CALIFICADA, 'demo.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <br>\n",
    "    <img src=\"./demo.jpg\"/>\n",
    "    <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Explica los siguientes resultados indicando verdadero o falso. Se puntuara si se contesta todas los √≠tems.\n",
    "\n",
    " * Para la regresi√≥n log√≠stica, con par√°metros optimizados mediante un m√©todo de gradiente estoc√°stico, establecer los par√°metros en $0$ es una inicializaci√≥n aceptable.\n",
    "\n",
    " * El uso de la validaci√≥n cruzada para seleccionar hiperpar√°metros garantizar√° que nuestro modelo no se sobreajuste.\n",
    "\n",
    " * Los algoritmos Bagging asignan pesos $w_1 \\dots, w_n$ a un conjunto de $N$ estudiantes d√©biles. Vuelven a ponderar a los alumnos y los convierten en fuertes. Los algoritmos Boosting extraen $N$ distribuciones de muestra (generalmente con reemplazo) de un conjunto de datos original para que los alumnos se entrenen.\n",
    "\n",
    " * Un √°rbol de decisi√≥n binario de profundidad infinita siempre puede alcanzar el $100\\%$ de exactitud en el entrenamiento, siempre que ning√∫n punto est√© mal etiquetado en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Verdadero, solo para el caso de una regresi√≥n logistica, incluso si los pesos se ponen en 0, lo logra una convergencia mediante SGD. Sin embargo esto no es cierto en redes neuronales, pues no permite realizar el proceso de backpropagation.\n",
    "\n",
    "b) Falso, si bien muchas veces es usado como t√©cnica para combatir el sobreajuste, no funcionar√° bien con datos externos si los datos que tiene no son representativos de los datos que intentar√° predecir.\n",
    "\n",
    "c) Falso, las definiciones estan intercambiadas. Boosting trata de a√±adir nuevos modelos que funcionan bien donde los modelos anteriores carecen.\n",
    "\n",
    "d) Verdad, esto es cierto para una profundidad infinita, pues cada divisi√≥n binaria interna dentro del √°rbol por cada nivel se ajusta perfectamente a todos los datos de entrenamiento, sin embargo no se logra una generalizaci√≥n para los datos de prueba, debido a que se esta sobreajustando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Se podr√≠a perforar un pozo de petr√≥leo en la granja del profesor Neapolitan en Texas. Con base en lo que ha sucedido en granjas similares, juzgamos que la probabilidad de que haya petr√≥leo presente es de $0.5$, la probabilidad de que solo est√© presente gas natural es de $0.2$ y la probabilidad de que ninguno de los dos est√© presente es de $0.3$. Si hay petr√≥leo presente, una prueba geol√≥gica dar√° un resultado positivo con probabilidad de $0.9$,  si solo hay gas natural, dar√° un resultado positivo con probabilidad $0.3$  y si ninguno est√° presente, la prueba ser√° positiva con probabilidad $0.1$. Supongamos que la prueba resulta positiva. Utilice el teorema de Bayes para calcular la probabilidad de que haya petr√≥leo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pet: hay petroleo 1 , no hay petroleo 0\n",
    "Gas: hay gas 1, no hay gas 0\n",
    "Res: positivo 1, negativo 0\n",
    "\n",
    "Datos:\n",
    "    P(Pet=1) = 0.5  \n",
    "    P(Gas=1) = 0.2\n",
    "    P(Pet=0, Gas=0) = P(nada) = 0.3\n",
    "    P(Res=1 | Pet=1) = 0.9\n",
    "    P(Res=1 | Gas=1) = 0.3\n",
    "    P(Res=1 | Pet=0, Gas=0) = P(Res=1 | nada) = 0.1\n",
    "    \n",
    "Calcular P(Pet=1 | Res =1)\n",
    "\n",
    "Usando el teorema de Bayes:\n",
    "    ùëÉ(Pet=1|Res=1) = ùëÉ(Res=1|Pet=1) * ùëÉ(Pet=1) / ùëÉ(Res=1) \n",
    "    \n",
    "De los datos tenemos:\n",
    "    ùëÉ(Res=1|Pet=1) = 0.9\n",
    "    ùëÉ(Pet=1) = 0.5\n",
    "    \n",
    "    ùëÉ(Pet=1|Res=1) = 0.9 * 0.5 / ùëÉ(Res=1)   .... (*)\n",
    "\n",
    "Ahora hallaremos ùëÉ(Res=1):\n",
    "    ùëÉ(Res=1) = ùëÉ(Res=1|Pet=1)*P(Pet=1) + ùëÉ(Res=1|gas=1)*P(gas) + P(Res=1 | nada) ùëÉ(nada)  = 0.9*0.5 + 0.3*0.2 + 0.1*0.3 =   ...(**)\n",
    "    \n",
    "\n",
    "Finalmente en (*):\n",
    "    ùëÉ(Pet=1|Res=1) = 0.9 * 0.5 / \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 . Se te proporciona un modelo de Bayes, que se muestra a continuaci√≥n, con la etiqueta $Y$ y las caracter√≠sticas $X_1$ y $X_2$. Las probabilidades condicionales del modelo est√°n parametrizadas por $p_1$, $p_2$ y $q$.\n",
    "\n",
    "![](NaiveBayes.png)\n",
    "\n",
    "Ten en cuenta que algunos de los par√°metros son compartidos (por ejemplo, $P(X_1 = 0|Y = 0)=P(X_1 = 1|Y = 1) = p_1$).\n",
    "\n",
    "\n",
    "Dado un nuevo punto de dato con $X_1 = 1$ y $X_2 = 1$, ¬øcu√°l es la probabilidad de que este punto tenga la etiqueta $Y = 1$? Expresa tu respuesta en t√©rminos de los par√°metros $p_1$, $p_2$ y $q$ (es posible que no los necesite todos). Es decir debes calcular : $P(Y= 1| X_1= 1,X_2= 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <br>\n",
    "    <img src=\"https://economipedia.com/wp-content/uploads/Teorema-de-Bayes-1.png\"/>\n",
    "    <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ùëÉ(ùëå=1|ùëã1=1,ùëã2=1) = ùëÉ(ùëå=1|ùëã1=1)ùëÉ(ùëå=1|ùëã2=1)  .... (*)\n",
    "\n",
    "-> usando el teorema de Bayes\n",
    "\n",
    "a)\n",
    "\n",
    "ùëÉ(ùëå=1|ùëã1=1) = ùëÉ(ùëã1=1|ùëå=1)* ùëÉ(ùëå=1) / ùëÉ(ùëã1=1) = p1 * q / ùëÉ(ùëã1=1)\n",
    "-> ùëÉ(ùëã1=1) = ((1-p1)*(1-q) + p1*q)\n",
    "\n",
    "finalmente ->  ùëÉ(ùëå=1|ùëã1=1) = p1 * q / ((1-p1)*(1-q) + p1*q)\n",
    "\n",
    "b)\n",
    "\n",
    "ùëÉ(ùëå=1|ùëã2=1) = ùëÉ(ùëã2=1|ùëå=1)* ùëÉ(ùëå=1) / ùëÉ(ùëã2=1) = p2 * q / ùëÉ(ùëã2=1)\n",
    "-> ùëÉ(ùëã2=1) = ((1-p2)*(1-q) + p2*q)\n",
    "finalmente ->  ùëÉ(ùëå=1|ùëã2=1) = p2 * q / ((1-p2)*(1-q) + p2*q)\n",
    "\n",
    "uniendo a y b en (*) tenemos:\n",
    "   ùëÉ(ùëå=1|ùëã1=1,ùëã2=1) = ùëÉ(ùëå=1|ùëã1=1)ùëÉ(ùëå=1|ùëã2=1) = p1 * q * p2 * q  = p1*p2*(q^2) / (((1-p1)*(1-q) + p1*q) * ((1-p2)*(1-q) + p2*q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Explica los siguientes resultados indicando verdadero o falso. Se puntuara si se contesta todas los √≠tems.\n",
    "\n",
    "  * La acci√≥n realizada por un agente racional siempre ser√° una funci√≥n determinista de las percepciones actuales del agente.\n",
    "\n",
    " * Una ruta de soluci√≥n √≥ptima para un problema de b√∫squeda con costos positivos nunca tendr√° estados repetidos.\n",
    "\n",
    " * Si dos heur√≠sticas de b√∫squeda $h_1(s)$ y $h_2(s)$ tienen el mismo valor promedio, la heur√≠stica $h_3(s) = \\max (h_1(s), h_2(s))$ podr√≠a dar una mejor eficiencia $A^*$ que $h_1$ o $h_2$.\n",
    "\n",
    " * Para cualquier conjunto de atributos, y cualquier conjunto de entrenamiento generado por una funci√≥n determinista para esos atributos, existe un √°rbol de decisiones que es consistente con ese conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Verdadero, un agente racional debe \"hacer lo correcto\", en funci√≥n de lo que pueda percibir actualmente y las acciones que puede realizar. La acci√≥n correcta es la uno que har√° que el agente tenga m√°s √©xito, dicha acci√≥n se basa en reglas determin√≠sticas determinada por una funci√≥n determ√≠stica..\n",
    "\n",
    "b) Verdadero, en cualquier ruta de soluci√≥n con estados que se repiten n veces, eliminar un ciclo produce una ruta cuya soluci√≥n siempre tendra un costo mucho menor. \n",
    "c) Verdadero, si tienen el mismo valor promedio entonces existe un g(s) = 1/2 h1(s) + 1/2 h2(s). Sea h^‚àó(s) la verdadera distancia desde s. Sabemos que h1(s)‚â§h^‚àó(s) y h2(s)‚â§h ‚àó (s), entonces g(s) = 1/2 h1(s) + 1/2 h2(s) ‚â§ 1/2 h^‚àó(s) + 1/2 h^‚àó(s ) = h^‚àó(s)\n",
    "d) Verdadero, debido a que los atributos de ese conjunto de entrenamiento se puede reducir en condiciones binarias que pueden ser modelado por un √°rbol de decisi√≥n de determinado nivel o altura H. Para un √°rbol de profundidad infinita, siempre se converger√° a un modelamiento de dichos atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 . Usaremos el conjunto de datos [*Breast Cancer Wisconsin (Diagnostic)*](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/version/2), llamado `data.csv`\n",
    "\n",
    " * ¬øCu√°ntas observaciones (filas) hay en el conjunto de datos?\n",
    " * Asigna a una lista de nombre `feature_columns` todas las columnas del conjunto de datos menos el `id` de cada observaci√≥n y la clase `diagnosis` que es la que buscaremos predecir.\n",
    " * Crea una nueva columna `'target'` que tenga un valor num√©rico de `+1` en las muestras positivas (cuando el diagn√≥stico sea maligno) y `-1` en las muestra negativas (diagn√≥stico benigno).\n",
    " * Empleando `sklearn.model_selection.train_test_split` separa el conjunto de datos en un 90% para entrenamiento y validaci√≥n (`X_trainval`, `y_trainval`), y 10% para pruebas (`X_test`, `y_test`).\n",
    "\n",
    "   Luego separa (`X_trainval`, `y_trainval`) en un 80% para entrenamiento (`X_train`, `y_train`) y 20% para validaci√≥n (`X_val`, `y_val`).\n",
    "   \n",
    "* Empleando `sklearn.preprocessing.StandardScaler` se ha normalizado en un arreglo `X_trainval_scaled` el conjunto de entrenamiento y validaci√≥n. Usa `sklearn.decomposition.PCA` para calcular los vectores de carga **`pca_loadings`** y el puntaje **`pca_scores`** de cada observaci√≥n en el espacio de los componentes principales.\n",
    "\n",
    "* Crea una instancia de la clase `sklearn.linear_model.LogisticRegression` y ajusta un modelo con el conjunto de **entrenamiento**\n",
    "\n",
    "* Usa el modelo para predecir la probabilidad de que cada una de las observaciones de conjunto de **validaci√≥n** corresponda a la clase positiva (diagn√≥stico maligno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datos = pd.read_csv(\"data.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "datos.info()\n",
    "\n",
    "# vemos en la parte inferior que tenemos 569 filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0       1        17.99         10.38          122.80     1001.0   \n",
       "1       1        20.57         17.77          132.90     1326.0   \n",
       "2       1        19.69         21.25          130.00     1203.0   \n",
       "3       1        11.42         20.38           77.58      386.1   \n",
       "4       1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modificamos los targets\n",
    "\n",
    "datos.diagnosis.replace('B', -1,inplace=True)\n",
    "datos.diagnosis.replace('M', 1,inplace=True)\n",
    "\n",
    "# eliminamos la columna de id\n",
    "datos = datos.drop([\"id\", \"Unnamed: 32\"], axis=1)\n",
    "\n",
    "# renombramos la columna diagnosis por target\n",
    "datos.rename(columns={'diagnosis':'target'}, \n",
    "                 inplace=True)\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.11890</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08902</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08758</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.17300</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07678</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fractal_dimension_worst  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0                  0.11890        17.99         10.38          122.80   \n",
       "1                  0.08902        20.57         17.77          132.90   \n",
       "2                  0.08758        19.69         21.25          130.00   \n",
       "3                  0.17300        11.42         20.38           77.58   \n",
       "4                  0.07678        20.29         14.34          135.10   \n",
       "\n",
       "   area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0     1001.0          0.11840           0.27760          0.3001   \n",
       "1     1326.0          0.08474           0.07864          0.0869   \n",
       "2     1203.0          0.10960           0.15990          0.1974   \n",
       "3      386.1          0.14250           0.28390          0.2414   \n",
       "4     1297.0          0.10030           0.13280          0.1980   \n",
       "\n",
       "   concave points_mean  symmetry_mean  ...  radius_worst  texture_worst  \\\n",
       "0              0.14710         0.2419  ...         25.38          17.33   \n",
       "1              0.07017         0.1812  ...         24.99          23.41   \n",
       "2              0.12790         0.2069  ...         23.57          25.53   \n",
       "3              0.10520         0.2597  ...         14.91          26.50   \n",
       "4              0.10430         0.1809  ...         22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  target  \n",
       "0           0.7119                0.2654          0.4601       1  \n",
       "1           0.2416                0.1860          0.2750       1  \n",
       "2           0.4504                0.2430          0.3613       1  \n",
       "3           0.6869                0.2575          0.6638       1  \n",
       "4           0.4000                0.1625          0.2364       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambiamos el orden de las columnas\n",
    "cols = datos.columns.tolist()\n",
    "\n",
    "cols[0], cols[30] = cols[30], cols[0]\n",
    "\n",
    "datos = datos[cols]\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fractal_dimension_worst', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst']\n"
     ]
    }
   ],
   "source": [
    "# ahora creamos la lista feature_columns\n",
    "feature_columns = datos.columns.tolist()[0:-1]\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (409, 30)  y_train shape(409,)\n",
      "\n",
      "X_val shape: (103, 30)\t y_val shape(103,)\n",
      "\n",
      "X_test shape: (57, 30)\t y_test shape(57,)\n"
     ]
    }
   ],
   "source": [
    "# divisi√≥n de los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = datos.drop(\"target\", axis=1).values\n",
    "y = datos.target.values\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size = 0.1, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size = 0.2, random_state=0)\n",
    "\n",
    "print(\"X_train shape: {}  y_train shape{}\".format(X_train.shape, y_train.shape))\n",
    "print(\"\\nX_val shape: {}\\t y_val shape{}\".format(X_val.shape, y_val.shape))\n",
    "print(\"\\nX_test shape: {}\\t y_test shape{}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos e instanciamos el modelo de regresi√≥n\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# para el entrenamiento usaremos la mitad de las componentes totales de las caracter√≠sticas\n",
    "pca = PCA(n_components=15)\n",
    "\n",
    "logReg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), pca, logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=15)),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nota: \n",
    "No estamos usando el conjunto de validaci√≥n porque no usamos b√∫squeda de hiperpar√°metros (con grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje en el conjunto de entrenamiento: 0.987775\n",
      "Puntaje en el conjunto de validaci√≥n: 0.990291\n",
      "Puntaje en el conjunto de prueba: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# mostramos los puntajes alcanzados en el conjunto de entrenamiento, validaci√≥n y prueba\n",
    "print(\"Puntaje en el conjunto de entrenamiento: %f\" % model.score(X_train, y_train))\n",
    "print(\"Puntaje en el conjunto de validaci√≥n: %f\" % model.score(X_val, y_val))\n",
    "print(\"Puntaje en el conjunto de prueba: %f\" % model.score(X_test, y_test))\n",
    "\n",
    "# observamos que el modelo NO sufre de sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  [[6.788e-02 1.321e+01 2.525e+01 8.410e+01 5.379e+02 8.791e-02 5.205e-02\n",
      "  2.772e-02 2.068e-02 1.619e-01 5.584e-02 2.084e-01 1.350e+00 1.314e+00\n",
      "  1.758e+01 5.768e-03 8.082e-03 1.510e-02 6.451e-03 1.347e-02 1.828e-03\n",
      "  1.435e+01 3.423e+01 9.129e+01 6.329e+02 1.289e-01 1.063e-01 1.390e-01\n",
      "  6.005e-02 2.444e-01]]\n",
      "target:  [-1]\n",
      "predicci√≥n:  [-1]\n"
     ]
    }
   ],
   "source": [
    "# hacemos una predicci√≥n\n",
    "\n",
    "print(\"input: \", X_test[1:2])\n",
    "print(\"target: \", y_test[1:2])\n",
    "print(\"predicci√≥n: \", model.predict(X_test[1:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ahora nuestro modelo esta listo para predecir alguna de las siguientes clases\n",
    "model.classes_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.99      1.00      0.99        67\n",
      "     maligno       1.00      0.97      0.99        36\n",
      "\n",
      "    accuracy                           0.99       103\n",
      "   macro avg       0.99      0.99      0.99       103\n",
      "weighted avg       0.99      0.99      0.99       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = y_val\n",
    "y_pred = model.predict(X_val)\n",
    "target_names = [\"benigno\", \"maligno\"]  # 1 para maligno y -1 para benigno\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "# mirando el siguiente cuadro concluimos, usando la definici√≥n de precision (!= accuracy), de que una observaci√≥n corresponda\n",
    "# a la clase positiva (maligno) viene dada por 1.00 TP/TP+FP\n",
    "\n",
    "# nota: ESTOS RESULTADOS SON EN BASE AL CONJUNTO DE VALIDACI√ìN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puntos extras: Calcula las predicciones en el conjunto de validaci√≥n con un umbral de probabilidad `> 0.7`, indicando a continuaci√≥n la matriz de confusi√≥n, la exactitud, precisi√≥n, exhaustividad de las predicciones. Se provee la funci√≥n `print_binary_confusion_matrix` para mostrar la matriz de confusi√≥n. \n",
    "\n",
    "```\n",
    "from sklearn import metrics\n",
    "\n",
    "def print_binary_confusion_matrix(matrix):\n",
    "    TN = matrix[0,0]\n",
    "    FN = matrix[1,0]\n",
    "    FP = matrix[0,1]\n",
    "    TP = matrix[1,1]\n",
    "\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |   Predicci√≥n    |')\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |    +   |    -   |')\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "    print ('| Valor |  +  |  {:5d} |  {:5d} |'.format(TP, FN) )\n",
    "    print ('| real  +-----+--------+--------+')\n",
    "    print ('|       |  -  |  {:5d} |  {:5d} |'.format(FP, TN) )\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_binary_confusion_matrix(matrix):\n",
    "    TN = matrix[0,0]\n",
    "    FN = matrix[1,0]\n",
    "    FP = matrix[0,1]\n",
    "    TP = matrix[1,1]\n",
    "\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |   Predicci√≥n    |')\n",
    "    print ('              +-----------------+')\n",
    "    print ('              |    +   |    -   |')\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "    print ('| Valor |  +  |  {:5d} |  {:5d} |'.format(TP, FN) )\n",
    "    print ('| real  +-----+--------+--------+')\n",
    "    print ('|       |  -  |  {:5d} |  {:5d} |'.format(FP, TN) )\n",
    "    print ('+-------+-----+--------+--------+')\n",
    "    \n",
    "\n",
    "y_true = y_val\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              +-----------------+\n",
      "              |   Predicci√≥n    |\n",
      "              +-----------------+\n",
      "              |    +   |    -   |\n",
      "+-------+-----+--------+--------+\n",
      "| Valor |  +  |     35 |      1 |\n",
      "| real  +-----+--------+--------+\n",
      "|       |  -  |      0 |     67 |\n",
      "+-------+-----+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "print_binary_confusion_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
